{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PLDM for MiniGrid - Demo Notebook\n",
        "\n",
        "This notebook demonstrates all the functionality of the PLDM repository.\n",
        "\n",
        "Contents:\n",
        "1. Setup and Imports\n",
        "2. Using the Python API directly\n",
        "3. Training via command line\n",
        "4. Evaluation via command line\n",
        "5. Visualization via command line\n",
        "6. Working with pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure we're in the right directory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add repo to path if needed\n",
        "repo_path = os.path.dirname(os.path.abspath('.'))\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.insert(0, '.')\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import from our repo\n",
        "from models import PLDM, FlexibleEncoder, Predictor\n",
        "from utils import (\n",
        "    make_env, \n",
        "    get_full_obs, \n",
        "    bfs_solve, \n",
        "    collect_trajectory,\n",
        "    collect_dataset,\n",
        "    TrajectoryDataset,\n",
        "    vicreg_loss,\n",
        "    CEMPlanner,\n",
        "    make_custom_doorkey,\n",
        "    bfs_solve_custom_env,\n",
        "    generate_custom_configs\n",
        ")\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup device\n",
        "device = torch.device('mps' if torch.backends.mps.is_available() else \n",
        "                      'cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Using the Python API Directly\n",
        "\n",
        "This section shows how to use the modules directly in Python code.\n",
        "\n",
        "### 2.1 Environment Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create environment\n",
        "env = make_env(\"MiniGrid-DoorKey-5x5-v0\")\n",
        "env.reset(seed=42)\n",
        "\n",
        "# Get full observation\n",
        "obs = get_full_obs(env)\n",
        "print(f\"Observation shape: {obs.shape}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(obs)\n",
        "plt.title(\"MiniGrid-DoorKey-5x5-v0\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test BFS solver\n",
        "actions = bfs_solve(\"MiniGrid-DoorKey-5x5-v0\", seed=1)\n",
        "print(f\"BFS found solution with {len(actions)} actions: {actions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect a single trajectory\n",
        "traj = collect_trajectory(\"MiniGrid-DoorKey-5x5-v0\", seed=1, actions=actions)\n",
        "print(f\"Trajectory length: {len(traj)} steps\")\n",
        "print(f\"Keys in each step: {traj[0].keys()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect a small dataset (for demo - use more trajectories for real training)\n",
        "trajectories = collect_dataset(\n",
        "    env_name=\"MiniGrid-DoorKey-5x5-v0\",\n",
        "    num_trajectories=50,  # Small for demo\n",
        "    bfs_ratio=0.8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create PyTorch dataset\n",
        "dataset = TrajectoryDataset(trajectories, sequence_length=8)\n",
        "print(f\"Dataset size: {len(dataset)} sequences\")\n",
        "\n",
        "# Get a sample\n",
        "obs_seq, actions_seq, next_obs_seq = dataset[0]\n",
        "print(f\"Observation sequence shape: {obs_seq.shape}\")\n",
        "print(f\"Actions sequence shape: {actions_seq.shape}\")\n",
        "print(f\"Next observation sequence shape: {next_obs_seq.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create PLDM model\n",
        "model = PLDM(latent_dim=128, action_dim=7).to(device)\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test forward pass\n",
        "obs_batch = obs_seq.unsqueeze(0).to(device)  # Add batch dimension\n",
        "actions_batch = actions_seq.unsqueeze(0).to(device)\n",
        "next_obs_batch = next_obs_seq.unsqueeze(0).to(device)\n",
        "\n",
        "z, z_next, z_next_pred = model(obs_batch, actions_batch, next_obs_batch)\n",
        "print(f\"Latent z shape: {z.shape}\")\n",
        "print(f\"Predicted z_next shape: {z_next_pred.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test VICReg loss\n",
        "total_loss, sim_loss, std_loss, cov_loss = vicreg_loss(z_next_pred, z_next)\n",
        "print(f\"Total loss: {total_loss.item():.4f}\")\n",
        "print(f\"Similarity loss: {sim_loss.item():.4f}\")\n",
        "print(f\"Std loss: {std_loss.item():.4f}\")\n",
        "print(f\"Cov loss: {cov_loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 CEM Planner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create planner\n",
        "planner = CEMPlanner(\n",
        "    model, \n",
        "    action_dim=7, \n",
        "    horizon=10,\n",
        "    num_iterations=5,\n",
        "    num_samples=100,\n",
        "    num_elites=20\n",
        ")\n",
        "print(\"Planner created successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test planning (with random untrained model - just to verify it works)\n",
        "start_obs = trajectories[0][0]['obs']\n",
        "goal_obs = trajectories[0][-1]['obs']\n",
        "\n",
        "start_tensor = torch.FloatTensor(start_obs).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "goal_tensor = torch.FloatTensor(goal_obs).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    z_start = model.encode(start_tensor.to(device)).squeeze(0)\n",
        "    z_goal = model.encode(goal_tensor.to(device)).squeeze(0)\n",
        "    \n",
        "    planned_actions = planner.plan(z_start, z_goal, verbose=True)\n",
        "\n",
        "print(f\"\\nPlanned actions: {planned_actions.cpu().numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Custom Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate custom configurations\n",
        "custom_configs = generate_custom_configs(exclude_standard=True)\n",
        "print(f\"Generated {len(custom_configs)} custom configurations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and visualize a custom environment\n",
        "config = custom_configs[0]\n",
        "print(f\"Config: Key={config['key_pos']}, Door={config['door_pos']}, Goal={config['goal_pos']}\")\n",
        "\n",
        "custom_env = make_custom_doorkey(\n",
        "    key_pos=config['key_pos'],\n",
        "    door_pos=config['door_pos'],\n",
        "    goal_pos=config['goal_pos'],\n",
        "    agent_start=config['agent_start'],\n",
        "    agent_dir=0\n",
        ")\n",
        "custom_env.reset()\n",
        "\n",
        "custom_obs = get_full_obs(custom_env)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(custom_obs)\n",
        "plt.title(f\"Custom DoorKey: K={config['key_pos']}, D={config['door_pos']}, G={config['goal_pos']}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Test BFS solver on custom env\n",
        "custom_actions = bfs_solve_custom_env(custom_env)\n",
        "print(f\"BFS solution: {len(custom_actions)} actions\")\n",
        "\n",
        "custom_env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Environment Comparison (Generalization Environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize different MiniGrid environments used for generalization testing\n",
        "import gymnasium as gym\n",
        "\n",
        "env_names = [\n",
        "    \"MiniGrid-Empty-5x5-v0\",\n",
        "    \"MiniGrid-Empty-Random-5x5-v0\",\n",
        "    \"MiniGrid-Dynamic-Obstacles-5x5-v0\",\n",
        "    \"MiniGrid-DoorKey-5x5-v0\",\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "for i, env_name in enumerate(env_names):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    env.reset()\n",
        "    frame = env.render()\n",
        "    env.close()\n",
        "    \n",
        "    axes[i].imshow(frame)\n",
        "    short_name = env_name.replace(\"MiniGrid-\", \"\").replace(\"-v0\", \"\")\n",
        "    axes[i].set_title(short_name, fontsize=12, fontweight='bold')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('MiniGrid 5x5 Environments', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training via Command Line\n",
        "\n",
        "The following cells demonstrate how to train a model using the command line interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View training help\n",
        "!python train.py --help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a model with minimal settings (quick demo)\n",
        "# For real training, use more trajectories and epochs\n",
        "!python train.py \\\n",
        "    --output_dir outputs/demo_run \\\n",
        "    --num_trajectories 100 \\\n",
        "    --epochs 10 \\\n",
        "    --batch_size 32 \\\n",
        "    --val_every 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check what was saved\n",
        "import os\n",
        "for root, dirs, files in os.walk('outputs/demo_run'):\n",
        "    level = root.replace('outputs/demo_run', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files:\n",
        "        print(f'{subindent}{file}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation via Command Line\n",
        "\n",
        "The following cells demonstrate how to evaluate a trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View evaluation help\n",
        "!python evaluate.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic evaluation\n",
        "!python evaluate.py \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --num_episodes 10 \\\n",
        "    --output_dir outputs/demo_run/evaluation\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replanning frequency analysis\n",
        "!python evaluate.py \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --replan_analysis \\\n",
        "    --replan_values 1 3 6 \\\n",
        "    --num_episodes 10 \\\n",
        "    --output_dir outputs/demo_run/replan_analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test generalization to simpler environment\n",
        "!python evaluate.py \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --env_name MiniGrid-Empty-5x5-v0 \\\n",
        "    --num_episodes 10 \\\n",
        "    --output_dir outputs/demo_run/generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on custom DoorKey configurations\n",
        "!python evaluate.py \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --custom_configs \\\n",
        "    --num_trials_per_config 2 \\\n",
        "    --output_dir outputs/demo_run/custom_eval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization via Command Line\n",
        "\n",
        "The following cells demonstrate how to generate visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View visualization help\n",
        "!python visualize.py --help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate training curves\n",
        "!python visualize.py \\\n",
        "    --mode training_curves \\\n",
        "    --history_path outputs/demo_run/training_history.json \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate latent space visualization\n",
        "!python visualize.py \\\n",
        "    --mode latent_space \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --num_trajectories 50 \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate BFS trajectory visualizations\n",
        "!python visualize.py \\\n",
        "    --mode bfs_trajectories \\\n",
        "    --seeds 1 2 \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate planning episode visualization\n",
        "!python visualize.py \\\n",
        "    --mode planning \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate trajectory step-by-step visualization\n",
        "!python visualize.py \\\n",
        "    --mode trajectory \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate environment comparison visualization (shows different MiniGrid environments)\n",
        "!python visualize.py \\\n",
        "    --mode env_comparison \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate episode execution with distance trajectory plots\n",
        "# This shows both the step-by-step images AND the distance-to-goal plot\n",
        "!python visualize.py \\\n",
        "    --mode episode_distances \\\n",
        "    --model_path outputs/demo_run/checkpoints/best_model.pt \\\n",
        "    --output_dir outputs/demo_run/visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all generated visualizations\n",
        "import os\n",
        "viz_dir = 'outputs/demo_run/visualizations'\n",
        "if os.path.exists(viz_dir):\n",
        "    print(\"Generated visualizations:\")\n",
        "    for f in os.listdir(viz_dir):\n",
        "        print(f\"  - {f}\")\n",
        "else:\n",
        "    print(\"No visualizations directory found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Working with Pre-trained Models\n",
        "\n",
        "This section shows how to load and use a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a trained model\n",
        "model_path = 'outputs/demo_run/checkpoints/best_model.pt'\n",
        "\n",
        "# Create model and initialize encoder\n",
        "loaded_model = PLDM(latent_dim=128, action_dim=7).to(device)\n",
        "loaded_model.init_encoder_fc((3, 40, 40), device)  # Initialize FC layers\n",
        "\n",
        "# Load weights\n",
        "loaded_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the loaded model for planning\n",
        "planner_loaded = CEMPlanner(\n",
        "    loaded_model,\n",
        "    action_dim=7,\n",
        "    horizon=15,\n",
        "    num_iterations=10,\n",
        "    num_samples=200,\n",
        "    num_elites=30\n",
        ")\n",
        "\n",
        "# Get start and goal from a trajectory\n",
        "test_traj = collect_trajectory(\"MiniGrid-DoorKey-5x5-v0\", seed=5, \n",
        "                                actions=bfs_solve(\"MiniGrid-DoorKey-5x5-v0\", seed=5))\n",
        "\n",
        "start_obs = test_traj[0]['obs']\n",
        "goal_obs = test_traj[-1]['obs']\n",
        "\n",
        "# Visualize start and goal\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "axes[0].imshow(start_obs)\n",
        "axes[0].set_title('Start State')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(goal_obs)\n",
        "axes[1].set_title('Goal State')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plan with the loaded model\n",
        "start_tensor = torch.FloatTensor(start_obs).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "goal_tensor = torch.FloatTensor(goal_obs).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    z_start = loaded_model.encode(start_tensor.to(device)).squeeze(0)\n",
        "    z_goal = loaded_model.encode(goal_tensor.to(device)).squeeze(0)\n",
        "    \n",
        "    print(\"Planning...\")\n",
        "    planned_actions = planner_loaded.plan(z_start, z_goal, verbose=True)\n",
        "\n",
        "print(f\"\\nPlanned actions: {planned_actions.cpu().numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute planned actions in environment\n",
        "env = make_env(\"MiniGrid-DoorKey-5x5-v0\")\n",
        "env.reset(seed=5)\n",
        "\n",
        "execution_images = [get_full_obs(env).copy()]\n",
        "action_names = ['Left', 'Right', 'Fwd', 'Pick', 'Drop', 'Tog', 'Done']\n",
        "\n",
        "print(\"Executing planned actions:\")\n",
        "for i, action in enumerate(planned_actions.cpu().numpy()[:10]):  # First 10 actions\n",
        "    obs, reward, done, truncated, _ = env.step(int(action))\n",
        "    execution_images.append(get_full_obs(env).copy())\n",
        "    print(f\"  Step {i+1}: {action_names[action]}, reward={reward}, done={done}\")\n",
        "    if done:\n",
        "        print(\"  Goal reached!\")\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Visualize execution\n",
        "n_show = min(len(execution_images), 8)\n",
        "fig, axes = plt.subplots(1, n_show, figsize=(2*n_show, 2))\n",
        "for i in range(n_show):\n",
        "    axes[i].imshow(execution_images[i])\n",
        "    axes[i].set_title(f'Step {i}')\n",
        "    axes[i].axis('off')\n",
        "plt.suptitle('Planned Action Execution')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Full Training Run (Optional)\n",
        "\n",
        "Run this section for a more complete training run with better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full training run (takes longer but gives better results)\n",
        "# Uncomment to run\n",
        "\n",
        "# !python train.py \\\n",
        "#     --output_dir outputs/full_run \\\n",
        "#     --num_trajectories 1200 \\\n",
        "#     --epochs 100 \\\n",
        "#     --batch_size 64 \\\n",
        "#     --lr 3e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full evaluation after full training\n",
        "# Uncomment to run\n",
        "\n",
        "# !python evaluate.py \\\n",
        "#     --model_path outputs/full_run/checkpoints/best_model.pt \\\n",
        "#     --replan_analysis \\\n",
        "#     --replan_values 1 3 6 9 12 15 \\\n",
        "#     --num_episodes 50 \\\n",
        "#     --output_dir outputs/full_run/evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all visualizations after full training\n",
        "# Uncomment to run\n",
        "\n",
        "# !python visualize.py \\\n",
        "#     --mode all \\\n",
        "#     --model_path outputs/full_run/checkpoints/best_model.pt \\\n",
        "#     --history_path outputs/full_run/training_history.json \\\n",
        "#     --output_dir outputs/full_run/visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Python API**: Direct usage of models, utils, planners, and custom environments\n",
        "2. **Training**: `python train.py --output_dir <dir> [options]`\n",
        "3. **Evaluation**: `python evaluate.py --model_path <path> [options]`\n",
        "4. **Visualization**: `python visualize.py --mode <mode> [options]`\n",
        "5. **Loading models**: How to load and use pre-trained models\n",
        "\n",
        "Key arguments:\n",
        "- `--output_dir`: Where to save outputs (models, results, visualizations)\n",
        "- `--model_path`: Path to a saved model checkpoint\n",
        "- `--history_path`: Path to training history JSON\n",
        "- `--replan_analysis`: Run replanning frequency analysis\n",
        "- `--custom_configs`: Evaluate on custom DoorKey configurations\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jepa_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
